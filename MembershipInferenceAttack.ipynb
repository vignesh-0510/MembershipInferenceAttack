{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1_Mp5goI-AwdOwektNhYzo-0Vr6sv6szt",
      "authorship_tag": "ABX9TyPvGf+hGPGIpJ+y7G1OPDDS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "91614fba4197470fb9fc49989d5acdd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ddd2c0ef2222439683355ef4ee15ca85",
              "IPY_MODEL_2acbde4ee518458d9d7cf14c16abcf06",
              "IPY_MODEL_c60db0673ca04d0fbf0942fcc173786c"
            ],
            "layout": "IPY_MODEL_9ed66e9361a448ca8b6a622b6fddb180"
          }
        },
        "ddd2c0ef2222439683355ef4ee15ca85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd813fd6e0d64f45b1e06678d135f416",
            "placeholder": "​",
            "style": "IPY_MODEL_ee68d002cd4c4230be7082752e6db772",
            "value": "Map: 100%"
          }
        },
        "2acbde4ee518458d9d7cf14c16abcf06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ca6a5b226464712aa9f93f278febff9",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8907b5b23bc542afbe994b49a5aa3813",
            "value": 1000
          }
        },
        "c60db0673ca04d0fbf0942fcc173786c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_facaf39943634e5e93ac787404c498aa",
            "placeholder": "​",
            "style": "IPY_MODEL_3ecbe6e8a82046f19cbcb6e08111de23",
            "value": " 1000/1000 [00:00&lt;00:00, 1384.64 examples/s]"
          }
        },
        "9ed66e9361a448ca8b6a622b6fddb180": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd813fd6e0d64f45b1e06678d135f416": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee68d002cd4c4230be7082752e6db772": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ca6a5b226464712aa9f93f278febff9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8907b5b23bc542afbe994b49a5aa3813": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "facaf39943634e5e93ac787404c498aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ecbe6e8a82046f19cbcb6e08111de23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e928367f417c4baa9e498968d7568e4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b4b0a97d181e436f8492238f75c725d5",
              "IPY_MODEL_6905e4d3428945a1b37ab5c0ff452b6a",
              "IPY_MODEL_87f47df6ff29483ea55fc79360bd41dd"
            ],
            "layout": "IPY_MODEL_03ff76e9ab6340cda66174538ab83d73"
          }
        },
        "b4b0a97d181e436f8492238f75c725d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b47f8fac04f489e95dede912a4b1054",
            "placeholder": "​",
            "style": "IPY_MODEL_1e109a49eff74dcb8bc9e4254f6f2ff7",
            "value": "Map: 100%"
          }
        },
        "6905e4d3428945a1b37ab5c0ff452b6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ababb2e285f402197def9fa07f3d441",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e58136f9421648c8858bec5e4c8aa9f8",
            "value": 10000
          }
        },
        "87f47df6ff29483ea55fc79360bd41dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b342d155654b44639bcdf390d4fa2e89",
            "placeholder": "​",
            "style": "IPY_MODEL_2f17fc2d6fab4e52b7e67b4205da9a98",
            "value": " 10000/10000 [00:06&lt;00:00, 1977.04 examples/s]"
          }
        },
        "03ff76e9ab6340cda66174538ab83d73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b47f8fac04f489e95dede912a4b1054": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e109a49eff74dcb8bc9e4254f6f2ff7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ababb2e285f402197def9fa07f3d441": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e58136f9421648c8858bec5e4c8aa9f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b342d155654b44639bcdf390d4fa2e89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f17fc2d6fab4e52b7e67b4205da9a98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vignesh-0510/MembershipInferenceAttack/blob/main/MembershipInferenceAttack.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "VMRHuad6kr6u"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, get_linear_schedule_with_warmup\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Data and Model"
      ],
      "metadata": {
        "id": "6aD6cfBu8tOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_DIR = '/content/drive/MyDrive/PrivacyAwareComputing/ProjectMIALM'\n",
        "model_path = os.path.join(BASE_DIR, 'victim_model_distilbert_agnews')\n",
        "\n",
        "\n",
        "def load_victim(model_dir=\"victim_model\"):\n",
        "    model_path = os.path.join(BASE_DIR, model_dir)\n",
        "    tokenizer = DistilBertTokenizerFast.from_pretrained(model_path)\n",
        "    model = DistilBertForSequenceClassification.from_pretrained(model_path).to(device)\n",
        "    model.eval()\n",
        "    return model, tokenizer\n",
        "\n",
        "model, tokenizer = load_victim('victim_model_distilbert_agnews')"
      ],
      "metadata": {
        "id": "qlGdYSrSlRIG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(os.path.join(BASE_DIR, 'validation_samples.csv'))  # your uploaded file\n",
        "raw_ds = Dataset.from_pandas(df.rename(columns={\"label\": \"labels\"})[[\"text\", \"labels\"]])\n",
        "\n",
        "def tokenize_batch(batch):\n",
        "    return tokenizer(batch[\"text\"],truncation=True,padding=\"max_length\",max_length=256)\n",
        "\n",
        "shadow_source_ds = raw_ds.map(tokenize_batch, batched=True)\n",
        "shadow_source_ds = shadow_source_ds.remove_columns([\"text\"])  # only model inputs\n",
        "\n",
        "membership_data = np.loadtxt(os.path.join(BASE_DIR, 'validation_results.txt'), dtype=int)\n",
        "membership_data = membership_data[membership_data[:,0].argsort()]  # sort by index\n",
        "\n",
        "membership_labels = membership_data[:,1]  # array of 0/1\n",
        "print(\"Loaded membership labels:\", len(membership_labels))\n",
        "assert len(membership_labels) == len(raw_ds)\n",
        "\n",
        "member_idx = np.where(membership_labels == 1)[0].tolist()\n",
        "nonmember_idx = np.where(membership_labels == 0)[0].tolist()\n",
        "\n",
        "target_member_ds = shadow_source_ds.select(member_idx)\n",
        "target_nonmember_ds = shadow_source_ds.select(nonmember_idx)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "91614fba4197470fb9fc49989d5acdd7",
            "ddd2c0ef2222439683355ef4ee15ca85",
            "2acbde4ee518458d9d7cf14c16abcf06",
            "c60db0673ca04d0fbf0942fcc173786c",
            "9ed66e9361a448ca8b6a622b6fddb180",
            "dd813fd6e0d64f45b1e06678d135f416",
            "ee68d002cd4c4230be7082752e6db772",
            "4ca6a5b226464712aa9f93f278febff9",
            "8907b5b23bc542afbe994b49a5aa3813",
            "facaf39943634e5e93ac787404c498aa",
            "3ecbe6e8a82046f19cbcb6e08111de23"
          ]
        },
        "id": "7ygdQPO_l36f",
        "outputId": "cec1aabd-f19d-4b35-e942-e7003a2cbb24"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "91614fba4197470fb9fc49989d5acdd7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded membership labels: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_shadow_splits(dataset, num_shadows=5, shadow_train_frac=0.5, seed=0):\n",
        "    \"\"\"\n",
        "    dataset: Tokenized Dataset\n",
        "    Returns: list of (train_ds, out_ds) for each shadow\n",
        "    \"\"\"\n",
        "    rng = np.random.default_rng(seed)\n",
        "    n = len(dataset)\n",
        "    indices = np.arange(n)\n",
        "\n",
        "    shadow_pairs = []\n",
        "    for s in range(num_shadows):\n",
        "        rng.shuffle(indices)\n",
        "        cut = int(shadow_train_frac * n)\n",
        "        train_idx = indices[:cut]\n",
        "        out_idx   = indices[cut:]\n",
        "\n",
        "        train_ds = dataset.select(train_idx.tolist())\n",
        "        out_ds   = dataset.select(out_idx.tolist())\n",
        "        shadow_pairs.append((train_ds, out_ds))\n",
        "\n",
        "    return shadow_pairs"
      ],
      "metadata": {
        "id": "wEwvcLlDmFdW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    input_ids = torch.tensor([x[\"input_ids\"] for x in batch], dtype=torch.long)\n",
        "    attention_mask = torch.tensor([x[\"attention_mask\"] for x in batch], dtype=torch.long)\n",
        "    labels = torch.tensor([x[\"labels\"] for x in batch], dtype=torch.long)\n",
        "    return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"labels\": labels}\n",
        "\n",
        "def make_loader(ds, batch_size=16, shuffle=True):\n",
        "    return DataLoader(ds, batch_size=batch_size, shuffle=shuffle, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "O27ukyDHoptK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NoisyLabelCrossEntropy(nn.Module):\n",
        "    def __init__(self, noise_rate, num_classes):\n",
        "        super().__init__()\n",
        "        self.η = noise_rate\n",
        "        self.C = num_classes\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        log_probs = F.log_softmax(logits, dim=-1)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # construct noise-aware target distribution\n",
        "            true_dist = torch.zeros_like(log_probs)\n",
        "            true_dist.fill_(self.η / (self.C - 1))\n",
        "            true_dist.scatter_(1, targets.unsqueeze(1), 1 - self.η)\n",
        "\n",
        "        return torch.mean(torch.sum(-true_dist * log_probs, dim=-1))"
      ],
      "metadata": {
        "id": "6YPojKwcOxMd"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_shadow_model(victim_dir, train_ds, val_ds=None,\n",
        "                       epochs=2, lr=2e-5, batch_size=16, noise_rate=0.2):\n",
        "    \"\"\"\n",
        "    Each shadow shares same architecture & init as victim.\n",
        "    \"\"\"\n",
        "    model = DistilBertForSequenceClassification.from_pretrained(os.path.join(BASE_DIR, victim_dir)).to(device)\n",
        "    model.train()\n",
        "\n",
        "    train_loader = make_loader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = make_loader(val_ds, batch_size=batch_size, shuffle=False) if val_ds else None\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "    total_steps = epochs * len(train_loader)\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer, num_warmup_steps=int(0.1 * total_steps), num_training_steps=total_steps\n",
        "    )\n",
        "\n",
        "    # loss_fn = nn.CrossEntropyLoss(reduction=\"mean\")\n",
        "    loss_fn = NoisyLabelCrossEntropy(noise_rate=noise_rate, num_classes=4)\n",
        "\n",
        "    for ep in range(epochs):\n",
        "        running = 0.0\n",
        "        for batch in train_loader:\n",
        "            batch = {k:v.to(device) for k,v in batch.items()}\n",
        "            out = model(input_ids=batch[\"input_ids\"],\n",
        "                        attention_mask=batch[\"attention_mask\"])\n",
        "            loss = loss_fn(out.logits, batch[\"labels\"])\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            running += loss.item()\n",
        "\n",
        "        print(f\"[shadow] epoch {ep+1}/{epochs} loss={running/len(train_loader):.4f}\")\n",
        "\n",
        "    model.eval()\n",
        "    return model"
      ],
      "metadata": {
        "id": "eC-dgJlDouJn"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "@torch.no_grad()\n",
        "def extract_features(model, ds, batch_size=32):\n",
        "    loader = DataLoader(ds, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    all_features = []\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss(reduction=\"none\")\n",
        "\n",
        "    for batch in loader:\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attn = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attn, output_hidden_states=True)\n",
        "        logits = outputs.logits\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "        hidden = outputs.hidden_states[-1]  # last layer hidden state\n",
        "        cls_embed = hidden[:,0,:]\n",
        "\n",
        "        # 1. Loss\n",
        "        losses = loss_fn(logits, labels)\n",
        "\n",
        "        # 2. Confidence\n",
        "        conf = probs.max(dim=-1)[0]\n",
        "\n",
        "        # 3. Margin\n",
        "        top2 = torch.topk(probs, k=2, dim=-1).values\n",
        "        margin = top2[:, 0] - top2[:, 1]\n",
        "\n",
        "        # 4. Entropy\n",
        "        entr = -(probs * probs.log()).sum(dim=-1)\n",
        "\n",
        "        # 5. Correctness\n",
        "        preds = probs.argmax(dim=-1)\n",
        "        correct = (preds == labels).float()\n",
        "\n",
        "        # 6. Logit margin\n",
        "        top2 = torch.topk(probs, k=2, dim=-1).values\n",
        "        logit_margin = top2[:, 0] - top2[:, 1]\n",
        "\n",
        "        # 7. Logit norm\n",
        "        logit_norm = logits.norm(dim=-1)\n",
        "\n",
        "        # 8. Class norm\n",
        "\n",
        "        cls_norm = cls_embed.norm(dim=1)\n",
        "\n",
        "        feats = torch.stack([\n",
        "            losses,\n",
        "            conf,\n",
        "            # margin,\n",
        "            entr,\n",
        "            correct,\n",
        "            logit_margin,\n",
        "            # logit_norm,\n",
        "            # p_true,\n",
        "            # wrong_conf,\n",
        "            # cls_norm\n",
        "        ], dim=1)\n",
        "\n",
        "\n",
        "        # collect\n",
        "        all_features.append(feats.cpu().numpy())\n",
        "\n",
        "    # return shape (N, 5)\n",
        "    return np.concatenate(all_features, axis=0)"
      ],
      "metadata": {
        "id": "HKE66DdGouHJ"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_attack_dataset(victim_dir, shadow_pairs,\n",
        "                         shadow_epochs=2, batch_size=16, shadow_noise_rate=0.2, shadow_lr=2e-5):\n",
        "    \"\"\"\n",
        "    For each shadow:\n",
        "      - train on shadow train split (members)\n",
        "      - compute losses on members and non-members\n",
        "    Returns: X (losses), y (membership labels)\n",
        "    \"\"\"\n",
        "    X_list, y_list = [], []\n",
        "\n",
        "    for i, (in_ds, out_ds) in enumerate(shadow_pairs):\n",
        "        print(f\"\\n=== Training shadow {i+1}/{len(shadow_pairs)} ===\")\n",
        "        shadow_model = train_shadow_model(\n",
        "            victim_dir, in_ds, epochs=shadow_epochs, batch_size=batch_size, noise_rate=shadow_noise_rate, lr=shadow_lr\n",
        "        )\n",
        "\n",
        "        in_features  = extract_features(shadow_model, in_ds, batch_size=batch_size)\n",
        "        out_features = extract_features(shadow_model, out_ds, batch_size=batch_size)\n",
        "\n",
        "        X_list.append(in_features)\n",
        "        X_list.append(out_features)\n",
        "\n",
        "        y_list.append(np.ones(len(in_features)))      # members = 1\n",
        "        y_list.append(np.zeros(len(out_features)))      # members = 1\n",
        "\n",
        "    X = np.concatenate(X_list, axis=0).reshape(-1, in_features.shape[1])  # (M,1)\n",
        "    y = np.concatenate(y_list, axis=0).astype(np.int64)\n",
        "\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "SKoC6p-CouEe"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttackMLP(nn.Module):\n",
        "    def __init__(self, in_dim=5):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, 64),\n",
        "            nn.LayerNorm(64),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Dropout(0.2),\n",
        "\n",
        "            nn.Linear(64, 32),\n",
        "            nn.LayerNorm(32),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Dropout(0.2),\n",
        "\n",
        "            nn.Linear(32, 16),\n",
        "            nn.LeakyReLU(0.1),\n",
        "\n",
        "            nn.Linear(16, 1)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# def train_attack_model(X, y, epochs=20, lr=1e-4, batch_size=128):\n",
        "#     X_t = torch.tensor(X, dtype=torch.float32)\n",
        "#     y_t = torch.tensor(y, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "#     ds = torch.utils.data.TensorDataset(X_t, y_t)\n",
        "#     dl = DataLoader(ds, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "#     attack = AttackMLP(in_dim = X.shape[1]).to(device)\n",
        "#     opt = torch.optim.Adam(attack.parameters(), lr=lr)\n",
        "#     bce = nn.BCEWithLogitsLoss()\n",
        "#     print(f\"\\n=== Training attack ===\")\n",
        "#     for ep in range(epochs):\n",
        "#         running = 0.0\n",
        "#         for xb, yb in dl:\n",
        "#             xb, yb = xb.to(device), yb.to(device)\n",
        "#             logits = attack(xb)\n",
        "#             loss = bce(logits, yb)\n",
        "\n",
        "#             opt.zero_grad()\n",
        "#             loss.backward()\n",
        "#             opt.step()\n",
        "#             running += loss.item()\n",
        "#         if ep%(epochs//10) == 0:\n",
        "#           print(f\"[attack] epoch {ep+1}/{epochs} loss={running/len(dl):.4f}\")\n",
        "\n",
        "#     attack.eval()\n",
        "#     return attack"
      ],
      "metadata": {
        "id": "5ZtjaiGhouBz"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_attack_model(\n",
        "        X, y,\n",
        "        epochs=20,\n",
        "        lr=1e-4,\n",
        "        batch_size=128,\n",
        "        lbfgs_steps=10\n",
        "    ):\n",
        "    X_t = torch.tensor(X, dtype=torch.float32)\n",
        "    y_t = torch.tensor(y, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "    ds = torch.utils.data.TensorDataset(X_t, y_t)\n",
        "    dl = DataLoader(ds, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    attack = AttackMLP(in_dim=X.shape[1]).to(device)\n",
        "\n",
        "    # ---- Adam optimizer ----\n",
        "    opt = torch.optim.Adam(attack.parameters(), lr=lr)\n",
        "\n",
        "    # ---- LR Scheduler ----\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        opt,\n",
        "        mode=\"min\",\n",
        "        factor=0.5,\n",
        "        patience=2,\n",
        "        threshold=1e-3\n",
        "    )\n",
        "\n",
        "    bce = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    print(f\"\\n=== Training attack model (Adam + LBFGS) ===\")\n",
        "\n",
        "    for ep in range(epochs):\n",
        "\n",
        "        attack.train()\n",
        "        running = 0.0\n",
        "\n",
        "        # ----------------------------\n",
        "        #   PHASE 1 — Adam optimizer\n",
        "        # ----------------------------\n",
        "        for xb, yb in dl:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "\n",
        "            logits = attack(xb)\n",
        "            loss = bce(logits, yb)\n",
        "\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "            running += loss.item()\n",
        "\n",
        "        # LR scheduler step\n",
        "        scheduler.step(running / len(dl))\n",
        "\n",
        "        # Print every few epochs\n",
        "        if ep % max(1, epochs // 10) == 0:\n",
        "            print(f\"[Adam {ep+1}/{epochs}] loss = {running/len(dl):.4f}\")\n",
        "\n",
        "    # =====================================\n",
        "    #   PHASE 2 — LBFGS refinement\n",
        "    # =====================================\n",
        "\n",
        "    print(\"\\n=== Refining with LBFGS ===\")\n",
        "\n",
        "    # Define LBFGS optimizer (must use FULL batch!)\n",
        "    lbfgs = torch.optim.LBFGS(\n",
        "        attack.parameters(),\n",
        "        lr=0.1,               # LBFGS uses a different internal rule\n",
        "        max_iter=20,\n",
        "        history_size=50,\n",
        "        line_search_fn=\"strong_wolfe\"\n",
        "    )\n",
        "\n",
        "    full_x = X_t.to(device)\n",
        "    full_y = y_t.to(device)\n",
        "\n",
        "    def closure():\n",
        "        lbfgs.zero_grad()\n",
        "        logits = attack(full_x)\n",
        "        loss = bce(logits, full_y)\n",
        "        loss.backward()\n",
        "        return loss\n",
        "\n",
        "    # Perform LBFGS refinement steps\n",
        "    for i in range(lbfgs_steps):\n",
        "        loss_val = lbfgs.step(closure)\n",
        "        print(f\"  LBFGS step {i+1}/{lbfgs_steps}: loss={loss_val.item():.6f}\")\n",
        "\n",
        "    attack.eval()\n",
        "    return attack"
      ],
      "metadata": {
        "id": "VJffNAQDWuqN"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def attack_victim(attack_model, victim_model, member_ds, nonmember_ds, batch_size=32):\n",
        "    m_features = extract_features(victim_model, member_ds, batch_size=batch_size)\n",
        "    nm_features = extract_features(victim_model, nonmember_ds, batch_size=batch_size)\n",
        "\n",
        "    X_test = np.concatenate([m_features, nm_features], axis=0)\n",
        "    y_true = np.concatenate([\n",
        "        np.ones(len(m_features)),\n",
        "        np.zeros(len(nm_features))\n",
        "    ])\n",
        "\n",
        "    X_test_t = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
        "    probs = torch.sigmoid(attack_model(X_test_t)).cpu().numpy().squeeze()\n",
        "\n",
        "    y_pred = (probs > 0.5).astype(np.int64)\n",
        "    results = {}\n",
        "    results['accuracy'] = accuracy_score(y_true, y_pred)\n",
        "    results['roc_auc'] = float(roc_auc_score(y_true, probs))\n",
        "    results['precision'] = precision_score(y_true, y_pred)\n",
        "    results['recall'] = recall_score(y_true, y_pred)\n",
        "    results['f1'] = f1_score(y_true, y_pred)\n",
        "    results['confusion_matrix'] = confusion_matrix(y_true, y_pred)\n",
        "    # results['balanced_accuracy'] = balanced_accuracy_score(y_true, y_pred)\n",
        "\n",
        "    print(f\"\\nVictim attack accuracy: {results['accuracy']*100:.2f}% ROC AUC: {results['roc_auc']*100:.2f}%\")\n",
        "    return results, probs, y_true"
      ],
      "metadata": {
        "id": "V1N4-7RVot-q"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_loss_based_mia(\n",
        "    victim_dir,\n",
        "    shadow_source_ds,      # fake data pool for shadows\n",
        "    target_member_ds,      # fake members for evaluation\n",
        "    target_nonmember_ds,   # fake non-members for evaluation\n",
        "    num_shadows=5,\n",
        "    shadow_train_frac=0.5,\n",
        "    shadow_noise_rate=0.2,\n",
        "    shadow_epochs=10,\n",
        "    batch_size=16,\n",
        "    attack_model_epochs=20,\n",
        "    attack_lr=1e-4,\n",
        "    mode='validation'\n",
        "):\n",
        "\n",
        "    victim_model, tokenizer = load_victim(victim_dir)\n",
        "\n",
        "    shadow_pairs = make_shadow_splits(\n",
        "        shadow_source_ds,\n",
        "        num_shadows=num_shadows,\n",
        "        shadow_train_frac=shadow_train_frac\n",
        "    )\n",
        "\n",
        "    X_attack, y_attack = build_attack_dataset(\n",
        "        victim_dir, shadow_pairs,\n",
        "        shadow_epochs=shadow_epochs,\n",
        "        batch_size=batch_size,\n",
        "        shadow_noise_rate=shadow_noise_rate,\n",
        "        shadow_lr=1e-4\n",
        "    )\n",
        "\n",
        "    attack_model = train_attack_model(X_attack, y_attack, epochs=attack_model_epochs, lr=attack_lr)\n",
        "    if mode == 'validation':\n",
        "      results, probs, y_true = attack_victim(\n",
        "          attack_model, victim_model,\n",
        "          target_member_ds, target_nonmember_ds,\n",
        "          batch_size=batch_size\n",
        "      )\n",
        "      return attack_model, results\n",
        "    else:\n",
        "      return attack_model"
      ],
      "metadata": {
        "id": "HpilhxGBot2v"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mode = 'inference'\n",
        "attack_model, results = run_loss_based_mia(\n",
        "    victim_dir=\"victim_model_distilbert_agnews\",\n",
        "    shadow_source_ds=shadow_source_ds,\n",
        "    target_member_ds=target_member_ds,\n",
        "    target_nonmember_ds=target_nonmember_ds,\n",
        "    num_shadows=5,\n",
        "    shadow_train_frac=0.5,\n",
        "    shadow_noise_rate=0.02,\n",
        "    shadow_epochs=5,\n",
        "    batch_size=32,\n",
        "    attack_model_epochs=500,\n",
        "    attack_lr=1e-1,\n",
        "    mode=mode\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wS8jjiXzpCp9",
        "outputId": "479363fa-06c5-4fb3-c0c7-c4df5030a4b7"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Training shadow 1/5 ===\n",
            "[shadow] epoch 1/5 loss=0.3809\n",
            "[shadow] epoch 2/5 loss=0.2907\n",
            "[shadow] epoch 3/5 loss=0.2314\n",
            "[shadow] epoch 4/5 loss=0.2035\n",
            "[shadow] epoch 5/5 loss=0.1755\n",
            "\n",
            "=== Training shadow 2/5 ===\n",
            "[shadow] epoch 1/5 loss=0.4507\n",
            "[shadow] epoch 2/5 loss=0.3685\n",
            "[shadow] epoch 3/5 loss=0.2820\n",
            "[shadow] epoch 4/5 loss=0.2412\n",
            "[shadow] epoch 5/5 loss=0.1899\n",
            "\n",
            "=== Training shadow 3/5 ===\n",
            "[shadow] epoch 1/5 loss=0.4511\n",
            "[shadow] epoch 2/5 loss=0.3517\n",
            "[shadow] epoch 3/5 loss=0.2858\n",
            "[shadow] epoch 4/5 loss=0.2225\n",
            "[shadow] epoch 5/5 loss=0.2025\n",
            "\n",
            "=== Training shadow 4/5 ===\n",
            "[shadow] epoch 1/5 loss=0.4762\n",
            "[shadow] epoch 2/5 loss=0.3395\n",
            "[shadow] epoch 3/5 loss=0.2594\n",
            "[shadow] epoch 4/5 loss=0.2195\n",
            "[shadow] epoch 5/5 loss=0.1801\n",
            "\n",
            "=== Training shadow 5/5 ===\n",
            "[shadow] epoch 1/5 loss=0.4593\n",
            "[shadow] epoch 2/5 loss=0.3155\n",
            "[shadow] epoch 3/5 loss=0.2551\n",
            "[shadow] epoch 4/5 loss=0.2250\n",
            "[shadow] epoch 5/5 loss=0.2087\n",
            "\n",
            "=== Training attack model (Adam + LBFGS) ===\n",
            "[Adam 1/1000] loss = 0.7002\n",
            "[Adam 101/1000] loss = 0.6652\n",
            "[Adam 201/1000] loss = 0.6659\n",
            "[Adam 301/1000] loss = 0.6646\n",
            "[Adam 401/1000] loss = 0.6650\n",
            "[Adam 501/1000] loss = 0.6681\n",
            "[Adam 601/1000] loss = 0.6739\n",
            "[Adam 701/1000] loss = 0.6649\n",
            "[Adam 801/1000] loss = 0.6659\n",
            "[Adam 901/1000] loss = 0.6655\n",
            "\n",
            "=== Refining with LBFGS ===\n",
            "  LBFGS step 1/10: loss=0.665023\n",
            "  LBFGS step 2/10: loss=0.666383\n",
            "  LBFGS step 3/10: loss=0.666076\n",
            "  LBFGS step 4/10: loss=0.666695\n",
            "  LBFGS step 5/10: loss=0.667545\n",
            "  LBFGS step 6/10: loss=0.666312\n",
            "  LBFGS step 7/10: loss=0.667093\n",
            "  LBFGS step 8/10: loss=0.666556\n",
            "  LBFGS step 9/10: loss=0.665071\n",
            "  LBFGS step 10/10: loss=0.665395\n",
            "\n",
            "Victim attack accuracy: 39.40% ROC AUC: 52.12%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zs5ISf9SpCkg",
        "outputId": "7e6bea2e-c796-4538-a717-50e751dd3443"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.394,\n",
              " 'roc_auc': 0.5212104218234324,\n",
              " 'precision': 0.19736842105263158,\n",
              " 'recall': 0.703125,\n",
              " 'f1': 0.3082191780821918,\n",
              " 'confusion_matrix': array([[259, 549],\n",
              "        [ 57, 135]])}"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Draw Inference"
      ],
      "metadata": {
        "id": "WYGt9K8feoA6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mia_predict_from_df(df, tokenizer, victim_model, attack_model, batch_size=32):\n",
        "\n",
        "    # Step 1 — Convert DataFrame to HuggingFace Dataset\n",
        "    ds = Dataset.from_pandas(df[[\"text\", \"label\"]].rename(columns={\"label\": \"labels\"}))\n",
        "\n",
        "    # Step 2 — Tokenize\n",
        "    ds = ds.map(lambda batch: tokenizer(\n",
        "        batch[\"text\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=128\n",
        "    ), batched=True)\n",
        "\n",
        "    ds.set_format(\n",
        "        type=\"torch\",\n",
        "        columns=[\"input_ids\", \"attention_mask\", \"labels\"]\n",
        "    )\n",
        "\n",
        "    # Step 3 — Extract multi-feature MIA vectors\n",
        "    feats = extract_features(victim_model, ds, batch_size=batch_size)\n",
        "    # feats.shape = (N, feature_dim)\n",
        "\n",
        "    # Step 4 — Convert features to tensor\n",
        "    X = torch.tensor(feats, dtype=torch.float32).to(device)\n",
        "\n",
        "    # Step 5 — Predict membership probability\n",
        "    attack_model.eval()\n",
        "    probs = torch.sigmoid(attack_model(X)).cpu().numpy().squeeze()\n",
        "\n",
        "    # Step 6 — Convert to binary membership prediction\n",
        "    preds = (probs > 0.5).astype(int)\n",
        "\n",
        "    return probs, preds"
      ],
      "metadata": {
        "id": "R2HAlgxdQqsr"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv(os.path.join(BASE_DIR, 'sampled.csv'))"
      ],
      "metadata": {
        "id": "ny5W8ua7evrC"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, preds = mia_predict_from_df(test_df, tokenizer, model, attack_model, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 994,
          "referenced_widgets": [
            "e928367f417c4baa9e498968d7568e4a",
            "b4b0a97d181e436f8492238f75c725d5",
            "6905e4d3428945a1b37ab5c0ff452b6a",
            "87f47df6ff29483ea55fc79360bd41dd",
            "03ff76e9ab6340cda66174538ab83d73",
            "4b47f8fac04f489e95dede912a4b1054",
            "1e109a49eff74dcb8bc9e4254f6f2ff7",
            "4ababb2e285f402197def9fa07f3d441",
            "e58136f9421648c8858bec5e4c8aa9f8",
            "b342d155654b44639bcdf390d4fa2e89",
            "2f17fc2d6fab4e52b7e67b4205da9a98"
          ]
        },
        "id": "xHtTBVSve7So",
        "outputId": "b3028bbe-aab7-4cd0-ffd6-686083f9dfed"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e928367f417c4baa9e498968d7568e4a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "only integer tensors of a single element can be converted to an index",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3283454367.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmia_predict_from_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattack_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3240638104.py\u001b[0m in \u001b[0;36mmia_predict_from_df\u001b[0;34m(df, tokenizer, victim_model, attack_model, batch_size)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Step 3 — Extract multi-feature MIA vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvictim_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;31m# feats.shape = (N, feature_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-347742887.py\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(model, ds, batch_size)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"none\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    786\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    789\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1550939040.py\u001b[0m in \u001b[0;36mcollate_fn\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: only integer tensors of a single element can be converted to an index"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hz4tAzrqfElx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}